{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b35f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import cv2\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.ndimage import median_filter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde55ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(batch_size,base_dir, target_size=(64, 64)):\n",
    "    processed_images = []\n",
    "    img_dir = os.listdir(base_dir)\n",
    "    \n",
    "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
    "        batch_files = img_dir[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        for filename in batch_files:\n",
    "            filepath = os.path.join(base_dir, filename)\n",
    "            img = cv2.imread(filepath) # read image\n",
    "            img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) # resize image\n",
    "            batch_images.append(img)\n",
    "        \n",
    "        if not batch_images:\n",
    "            # nothing to process in this batch\n",
    "            continue\n",
    "        processed_images.extend(batch_images)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "\n",
    "def reduce_dimensions(images, reduction_method='pca', variance_threshold=0.95):\n",
    "    \"\"\"Apply dimension reduction using PCA or SVD\"\"\"\n",
    "    original_shape = images.shape\n",
    "    flattened = images.reshape(len(images), -1)\n",
    "    \n",
    "    if reduction_method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=variance_threshold)\n",
    "    else:\n",
    "        reducer = TruncatedSVD(n_components=min(flattened.shape))\n",
    "    \n",
    "    reduced = reducer.fit_transform(flattened)\n",
    "    reconstructed = reducer.inverse_transform(reduced)\n",
    "    variance_preserved = sum(reducer.explained_variance_ratio_) * 100\n",
    "    \n",
    "    print(f\"Variance preserved: {variance_preserved:.2f}%\")\n",
    "    return reconstructed.reshape(original_shape), variance_preserved\n",
    "\n",
    "def apply_convolution(image, kernel):\n",
    "    \"\"\"Apply convolution to an image\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        return np.stack([convolve2d(image[:,:,c], kernel, mode='same', boundary='wrap')\n",
    "                        for c in range(image.shape[2])], axis=2)\n",
    "    return convolve2d(image, kernel, mode='same', boundary='wrap')\n",
    "\n",
    "\n",
    "def get_convolution_kernels():\n",
    "    \"\"\"Return dictionary of common convolution kernels\"\"\"\n",
    "    return {\n",
    "        'edge_detection': np.array([[-1, -1, -1],\n",
    "                                  [-1,  8, -1],\n",
    "                                  [-1, -1, -1]]),\n",
    "        'sobel_x': np.array([[-1, 0, 1],\n",
    "                            [-2, 0, 2],\n",
    "                            [-1, 0, 1]]),\n",
    "        'sobel_y': np.array([[-1, -2, -1],\n",
    "                            [ 0,  0,  0],\n",
    "                            [ 1,  2,  1]]),\n",
    "        'color_contrast': np.array([[0, -1, 0],\n",
    "                                  [-1, 5, -1],\n",
    "                                  [0, -1, 0]])\n",
    "    }\n",
    "\n",
    "def apply_max_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply max pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.max(image[i*pool_size:(i+1)*pool_size, \n",
    "                                     j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def apply_avg_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply average pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.mean(image[i*pool_size:(i+1)*pool_size, \n",
    "                                      j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def flatten_batch(images):\n",
    "    \"\"\"Flatten batch of images\"\"\"\n",
    "    return images.reshape(len(images), -1)\n",
    "\n",
    "def remove_outliers(image, method='knn', n_neighbors=5, window_size=3):\n",
    "    \"\"\"Remove outliers from image using specified method\"\"\"\n",
    "    \n",
    "    original_shape = image.shape\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Handle different color channels separately\n",
    "    if len(original_shape) == 3:\n",
    "        cleaned_image = np.zeros_like(image)\n",
    "        for c in range(original_shape[2]):\n",
    "            cleaned_image[:,:,c] = remove_outliers(image[:,:,c], method, n_neighbors, window_size)\n",
    "        return cleaned_image\n",
    "    \n",
    "    if method.lower() == 'knn':\n",
    "        # Prepare data for KNN imputation\n",
    "        X = np.zeros((h*w, window_size**2))\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                # Extract local window\n",
    "                i_start = max(0, i - window_size//2)\n",
    "                i_end = min(h, i + window_size//2 + 1)\n",
    "                j_start = max(0, j - window_size//2)\n",
    "                j_end = min(w, j + window_size//2 + 1)\n",
    "                window = image[i_start:i_end, j_start:j_end].flatten()\n",
    "                # Pad if necessary\n",
    "                if len(window) < window_size**2:\n",
    "                    window = np.pad(window, (0, window_size**2 - len(window)), mode='edge')\n",
    "                X[i*w + j] = window\n",
    "        \n",
    "        # Apply KNN imputation\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        cleaned = imputer.fit_transform(X)\n",
    "        \n",
    "        # Reshape back to image\n",
    "        return cleaned[:,window_size**2//2].reshape(h, w)\n",
    "    \n",
    "    elif method.lower() == 'median':\n",
    "        return median_filter(image, size=window_size)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown outlier removal method: {method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb63759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = os.listdir('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1')\n",
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ab537b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 4284, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1/' + A[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177f8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10  # Adjust this number based on your available memory\n",
    "# Use the same absolute folder that was used to create A\n",
    "base_dir = r'E:/@IIT_BBS/@Sem 1/ML/Final Project/P1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fdeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_images = preprocess_images(batch_size=20,base_dir=base_dir, target_size=(64, 64))\n",
    "# processed_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e155ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imwrite('Processed Image.png', processed_images[9].astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Custom convolution application with multiple filters\n",
    "# ----------------------------------------------------------\n",
    "def apply_conv(image,kernel_size=3):\n",
    "    \"\"\"Apply a bank of convolutional filters and stack results as multi-channel image.\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "\n",
    "    filters = []\n",
    "\n",
    "    # Sobel filters\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    filters.extend([sobelx, sobely])\n",
    "\n",
    "    # Laplacian\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    filters.append(lap)\n",
    "\n",
    "    # Gabor filters (various orientations)\n",
    "    for theta in np.arange(0, np.pi, np.pi / 6):  # 6 orientations\n",
    "        kernel = cv2.getGaborKernel((11, 11), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
    "        fimg = cv2.filter2D(gray, cv2.CV_64F, kernel)\n",
    "        filters.append(fimg)\n",
    "\n",
    "    # Difference of Gaussians\n",
    "    g1 = cv2.GaussianBlur(gray, (3, 3), 1)\n",
    "    g2 = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "    dog = g1 - g2\n",
    "    filters.append(dog)\n",
    "\n",
    "    # Stack as multichannel image\n",
    "    stacked = np.stack(filters, axis=-1)\n",
    "\n",
    "    # Normalize each channel to 0-1\n",
    "    stacked = np.array([(ch - ch.min()) / (ch.max() - ch.min() + 1e-6) for ch in np.moveaxis(stacked, -1, 0)])\n",
    "    stacked = np.moveaxis(stacked, 0, -1)\n",
    "    # print(\"apply_conv is running....\")\n",
    "    return stacked\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Max pooling utility\n",
    "# ----------------------------------------------------------\n",
    "def apply_maxpooling(image, target_pool_size=8):\n",
    "    \"\"\"Apply pooling safely even when image has >4 channels.\"\"\"\n",
    "    pooled = image.copy().astype(np.float32)\n",
    "    if target_pool_size is None:\n",
    "        raise ValueError(\"target_size must be provided.\")\n",
    "\n",
    "    def safe_resize(image, new_w, new_h):\n",
    "        if image.ndim == 2 or image.shape[2] <= 4:\n",
    "            return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            resized_channels = [\n",
    "                cv2.resize(image[..., c], (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "                for c in range(image.shape[2])\n",
    "            ]\n",
    "            return np.stack(resized_channels, axis=-1)\n",
    "\n",
    "    while True:\n",
    "        h, w = pooled.shape[:2]\n",
    "        if min(h, w) <= target_pool_size:\n",
    "            break\n",
    "        pooled = safe_resize(pooled, max(1, w // 2), max(1, h // 2))\n",
    "    # print(\"apply_maxpooling is running....\")\n",
    "    return pooled\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Full feature extraction pipeline\n",
    "# ----------------------------------------------------------\n",
    "def feature_extraction(image, kernel_size=3, target_pool_size=7):\n",
    "    \"\"\"Extract rich handcrafted features using convolutional filter bank and pooling.\"\"\"\n",
    "    conv_output = apply_conv(image, kernel_size=kernel_size)\n",
    "    pooled_output = apply_maxpooling(conv_output, target_pool_size=target_pool_size)\n",
    "\n",
    "    # Flatten pooled output\n",
    "    features = pooled_output.flatten()\n",
    "\n",
    "    # Optionally add summary stats per channel (mean, std)\n",
    "    channel_means = pooled_output.mean(axis=(0, 1))\n",
    "    channel_stds = pooled_output.std(axis=(0, 1))\n",
    "\n",
    "    full_feature_vector = np.concatenate([features, channel_means, channel_stds])\n",
    "    # print(\"feature_extraction is running....\\n\")\n",
    "    return full_feature_vector\n",
    "\n",
    "\n",
    "# feats = feature_extraction(processed_images[9], kernel_size=3,target_pool_size=8)\n",
    "# print(feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd91353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_CFE(batch_size,base_dir, target_size=7):\n",
    "    \"\"\" Batch Custom Feature Extraction using convolutional filter bank \"\"\"\n",
    "    processed_images = []\n",
    "    img_dir = os.listdir(base_dir)\n",
    "    \n",
    "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
    "        batch_files = img_dir[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        for filename in batch_files:\n",
    "            filepath = os.path.join(base_dir, filename)\n",
    "            img = cv2.imread(filepath) # read image\n",
    "            img = feature_extraction(img, kernel_size=3,target_pool_size=target_size)\n",
    "            batch_images.append(img)\n",
    "        \n",
    "        if not batch_images:\n",
    "            # nothing to process in this batch\n",
    "            continue\n",
    "        processed_images.extend(batch_images)\n",
    "    return np.array(processed_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd8dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/22 [02:32<53:32, 152.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2/22 [05:07<51:21, 154.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3/22 [07:43<48:57, 154.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n",
      "apply_conv is running....\n",
      "apply_maxpooling is running....\n",
      "feature_extraction is running....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_features = batch_CFE(batch_size=20,base_dir=base_dir, target_size=8)\n",
    "batch_features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
