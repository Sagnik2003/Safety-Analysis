{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b35f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import cv2\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.ndimage import median_filter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde55ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(batch_size,base_dir, target_size=(64, 64)):\n",
    "    processed_images = []\n",
    "    img_dir = os.listdir(base_dir)\n",
    "    \n",
    "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
    "        batch_files = img_dir[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        for filename in batch_files:\n",
    "            filepath = os.path.join(base_dir, filename)\n",
    "            img = cv2.imread(filepath) # read image\n",
    "            img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) # resize image\n",
    "            batch_images.append(img)\n",
    "        \n",
    "        if not batch_images:\n",
    "            # nothing to process in this batch\n",
    "            continue\n",
    "        processed_images.extend(batch_images)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "\n",
    "def reduce_dimensions(images, reduction_method='pca', variance_threshold=0.95):\n",
    "    \"\"\"Apply dimension reduction using PCA or SVD\"\"\"\n",
    "    original_shape = images.shape\n",
    "    flattened = images.reshape(len(images), -1)\n",
    "    \n",
    "    if reduction_method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=variance_threshold)\n",
    "    else:\n",
    "        reducer = TruncatedSVD(n_components=min(flattened.shape))\n",
    "    \n",
    "    reduced = reducer.fit_transform(flattened)\n",
    "    reconstructed = reducer.inverse_transform(reduced)\n",
    "    variance_preserved = sum(reducer.explained_variance_ratio_) * 100\n",
    "    \n",
    "    print(f\"Variance preserved: {variance_preserved:.2f}%\")\n",
    "    return reconstructed.reshape(original_shape), variance_preserved\n",
    "\n",
    "def apply_convolution(image, kernel):\n",
    "    \"\"\"Apply convolution to an image\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        return np.stack([convolve2d(image[:,:,c], kernel, mode='same', boundary='wrap')\n",
    "                        for c in range(image.shape[2])], axis=2)\n",
    "    return convolve2d(image, kernel, mode='same', boundary='wrap')\n",
    "\n",
    "\n",
    "def get_convolution_kernels():\n",
    "    \"\"\"Return dictionary of common convolution kernels\"\"\"\n",
    "    return {\n",
    "        'edge_detection': np.array([[-1, -1, -1],\n",
    "                                  [-1,  8, -1],\n",
    "                                  [-1, -1, -1]]),\n",
    "        'sobel_x': np.array([[-1, 0, 1],\n",
    "                            [-2, 0, 2],\n",
    "                            [-1, 0, 1]]),\n",
    "        'sobel_y': np.array([[-1, -2, -1],\n",
    "                            [ 0,  0,  0],\n",
    "                            [ 1,  2,  1]]),\n",
    "        'color_contrast': np.array([[0, -1, 0],\n",
    "                                  [-1, 5, -1],\n",
    "                                  [0, -1, 0]])\n",
    "    }\n",
    "\n",
    "def apply_max_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply max pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.max(image[i*pool_size:(i+1)*pool_size, \n",
    "                                     j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def apply_avg_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply average pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.mean(image[i*pool_size:(i+1)*pool_size, \n",
    "                                      j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def flatten_batch(images):\n",
    "    \"\"\"Flatten batch of images\"\"\"\n",
    "    return images.reshape(len(images), -1)\n",
    "\n",
    "def remove_outliers(image, method='knn', n_neighbors=5, window_size=3):\n",
    "    \"\"\"Remove outliers from image using specified method\"\"\"\n",
    "    \n",
    "    original_shape = image.shape\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Handle different color channels separately\n",
    "    if len(original_shape) == 3:\n",
    "        cleaned_image = np.zeros_like(image)\n",
    "        for c in range(original_shape[2]):\n",
    "            cleaned_image[:,:,c] = remove_outliers(image[:,:,c], method, n_neighbors, window_size)\n",
    "        return cleaned_image\n",
    "    \n",
    "    if method.lower() == 'knn':\n",
    "        # Prepare data for KNN imputation\n",
    "        X = np.zeros((h*w, window_size**2))\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                # Extract local window\n",
    "                i_start = max(0, i - window_size//2)\n",
    "                i_end = min(h, i + window_size//2 + 1)\n",
    "                j_start = max(0, j - window_size//2)\n",
    "                j_end = min(w, j + window_size//2 + 1)\n",
    "                window = image[i_start:i_end, j_start:j_end].flatten()\n",
    "                # Pad if necessary\n",
    "                if len(window) < window_size**2:\n",
    "                    window = np.pad(window, (0, window_size**2 - len(window)), mode='edge')\n",
    "                X[i*w + j] = window\n",
    "        \n",
    "        # Apply KNN imputation\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        cleaned = imputer.fit_transform(X)\n",
    "        \n",
    "        # Reshape back to image\n",
    "        return cleaned[:,window_size**2//2].reshape(h, w)\n",
    "    \n",
    "    elif method.lower() == 'median':\n",
    "        return median_filter(image, size=window_size)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown outlier removal method: {method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb63759",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = os.listdir('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1')\n",
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = cv2.imread('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1/' + A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f330548",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('demo.png',demo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10  # Adjust this number based on your available memory\n",
    "# Use the same absolute folder that was used to create A\n",
    "base_dir = r'E:/@IIT_BBS/@Sem 1/ML/Final Project/P1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d560b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 12/43 [00:11<00:29,  1.05it/s]"
     ]
    }
   ],
   "source": [
    "process_img = preprocess_images(batch_size,base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_img,var_img =reduce_dimensions(preprocess_images(batch_size,base_dir), reduction_method='pca', variance_threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outlier_img = remove_outliers(red_img[30], method='knn', n_neighbors=5, window_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv2.imwrite(\"Reduced_image.png\", red_img[30])\n",
    "cv2.imwrite(\"Processed_image.png\", process_img[30])\n",
    "cv2.imwrite(\"Non_outlier_image.png\", non_outlier_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Custom convolution application with multiple filters\n",
    "# ----------------------------------------------------------\n",
    "def apply_conv(image, kernel_size=3):\n",
    "    \"\"\"Apply a bank of convolutional filters to each input channel and stack results as a multi-channel image.\n",
    "\n",
    "    Fix: ensure all intermediate OpenCV operations use a consistent depth (CV_32F) to avoid unsupported\n",
    "    source/destination format combinations.\n",
    "    \"\"\"\n",
    "    # Ensure list of single-channel arrays (use float32 consistently)\n",
    "    if image.ndim == 2:\n",
    "        channels = [image.copy().astype(np.float32)]\n",
    "    else:\n",
    "        channels = [image[..., c].astype(np.float32) for c in range(image.shape[2])]\n",
    "\n",
    "    filters = []\n",
    "\n",
    "    for ch in channels:\n",
    "        # Use CV_32F for all OpenCV ops to keep consistent dtypes\n",
    "        sobelx = cv2.Sobel(ch, cv2.CV_32F, 1, 0, ksize=kernel_size)\n",
    "        sobely = cv2.Sobel(ch, cv2.CV_32F, 0, 1, ksize=kernel_size)\n",
    "        filters.extend([sobelx, sobely])\n",
    "\n",
    "        # Laplacian with CV_32F\n",
    "        lap = cv2.Laplacian(ch, cv2.CV_32F)\n",
    "        filters.append(lap)\n",
    "\n",
    "        # Gabor filters (various orientations) - kernel as CV_32F, filter2D output CV_32F\n",
    "        for theta in np.arange(0, np.pi, np.pi / 6):  # 6 orientations\n",
    "            kernel = cv2.getGaborKernel((11, 11), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
    "            fimg = cv2.filter2D(ch, cv2.CV_32F, kernel)\n",
    "            filters.append(fimg)\n",
    "\n",
    "        # Difference of Gaussians (Gaussian retains float32)\n",
    "        g1 = cv2.GaussianBlur(ch, (3, 3), 1)\n",
    "        g2 = cv2.GaussianBlur(ch, (5, 5), 2)\n",
    "        dog = g1 - g2\n",
    "        filters.append(dog)\n",
    "\n",
    "    # Stack as multichannel image: H x W x (num_filters * num_input_channels)\n",
    "    # Ensure everything is float32 before stacking\n",
    "    filters = [f.astype(np.float32) for f in filters]\n",
    "    stacked = np.stack(filters, axis=-1)\n",
    "\n",
    "    # Normalize each channel to 0-1 safely\n",
    "    stacked = np.moveaxis(stacked, -1, 0)\n",
    "    normed = []\n",
    "    for ch in stacked:\n",
    "        mn = ch.min()\n",
    "        mx = ch.max()\n",
    "        if mx - mn < 1e-6:\n",
    "            normed.append(np.zeros_like(ch))\n",
    "        else:\n",
    "            normed.append((ch - mn) / (mx - mn))\n",
    "    stacked = np.moveaxis(np.array(normed, dtype=np.float32), 0, -1)\n",
    "    return stacked\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Max pooling utility\n",
    "# ----------------------------------------------------------\n",
    "def apply_maxpooling(image, target_pool_size=8):\n",
    "    \"\"\"Apply pooling safely even when image has >4 channels, ensuring a fixed output spatial size.\"\"\"\n",
    "    pooled = image.copy().astype(np.float32)\n",
    "    if target_pool_size is None:\n",
    "        raise ValueError(\"target_pool_size must be provided.\")\n",
    "\n",
    "    def safe_resize(image, new_w, new_h):\n",
    "        if image.ndim == 2 or image.shape[2] <= 4:\n",
    "            return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            resized_channels = [\n",
    "                cv2.resize(image[..., c], (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "                for c in range(image.shape[2])\n",
    "            ]\n",
    "            return np.stack(resized_channels, axis=-1)\n",
    "\n",
    "    # Iteratively reduce size until dimensions are close to target_pool_size\n",
    "    while True:\n",
    "        h, w = pooled.shape[:2]\n",
    "        if h <= target_pool_size and w <= target_pool_size: # Stop if both dimensions are <= target\n",
    "            break\n",
    "        # Reduce by half, ensuring dimensions don't become zero\n",
    "        pooled = safe_resize(pooled, max(1, w // 2), max(1, h // 2))\n",
    "\n",
    "    # Final resize to ensure exact target_pool_size x target_pool_size spatial dimensions\n",
    "    # This handles cases where pooled might be (7,7) or (9,9) after the loop, for target_pool_size=8\n",
    "    if pooled.shape[0] != target_pool_size or pooled.shape[1] != target_pool_size:\n",
    "        pooled = safe_resize(pooled, target_pool_size, target_pool_size)\n",
    "\n",
    "    # print(\"apply_maxpooling is running....\")\n",
    "    return pooled\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Full feature extraction pipeline\n",
    "# ----------------------------------------------------------\n",
    "def feature_extraction(image, kernel_size=3, target_pool_size=7):\n",
    "    \"\"\"Extract rich handcrafted features using convolutional filter bank and pooling.\"\"\"\n",
    "    conv_output = apply_conv(image, kernel_size=kernel_size)\n",
    "    pooled_output = apply_maxpooling(conv_output, target_pool_size=target_pool_size)\n",
    "\n",
    "    # Flatten pooled output\n",
    "    features = pooled_output.flatten()\n",
    "\n",
    "    # Optionally add summary stats per channel (mean, std)\n",
    "    channel_means = pooled_output.mean(axis=(0, 1))\n",
    "    channel_stds = pooled_output.std(axis=(0, 1))\n",
    "\n",
    "    full_feature_vector = np.concatenate([features, channel_means, channel_stds])\n",
    "    # print(\"feature_extraction is running....\\n\")\n",
    "    return full_feature_vector\n",
    "\n",
    "\n",
    "# feats = feature_extraction(processed_images[9], kernel_size=3,target_pool_size=8)\n",
    "# print(feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd91353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_CFE(batch_size,base_dir, target_size=7):\n",
    "    \"\"\" Batch Custom Feature Extraction using convolutional filter bank \"\"\"\n",
    "    processed_images = []\n",
    "    img_dir = os.listdir(base_dir)\n",
    "\n",
    "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
    "        batch_files = img_dir[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        for filename in batch_files:\n",
    "            filepath = os.path.join(base_dir, filename)\n",
    "            img = cv2.imread(filepath) # read image\n",
    "            img = feature_extraction(img, kernel_size=3,target_pool_size=target_size)\n",
    "            batch_images.append(img)\n",
    "\n",
    "        if not batch_images:\n",
    "            # nothing to process in this batch\n",
    "            continue\n",
    "        processed_images.extend(batch_images)\n",
    "    return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features = batch_CFE(batch_size=20,base_dir=base_dir, target_size=5)\n",
    "batch_features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
