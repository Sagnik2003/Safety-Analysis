{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b35f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import cv2\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.ndimage import median_filter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde55ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(batch_size,base_dir, target_size=(64, 64)):\n",
    "    processed_images = []\n",
    "    img_dir = os.listdir(base_dir)\n",
    "    \n",
    "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
    "        batch_files = img_dir[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        for filename in batch_files:\n",
    "            filepath = os.path.join(base_dir, filename)\n",
    "            img = cv2.imread(filepath) # read image\n",
    "            img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) # resize image\n",
    "            batch_images.append(img)\n",
    "        \n",
    "        if not batch_images:\n",
    "            # nothing to process in this batch\n",
    "            continue\n",
    "        processed_images.extend(batch_images)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "\n",
    "def reduce_dimensions(images, reduction_method='pca', variance_threshold=0.95):\n",
    "    \"\"\"Apply dimension reduction using PCA or SVD\"\"\"\n",
    "    original_shape = images.shape\n",
    "    flattened = images.reshape(len(images), -1)\n",
    "    \n",
    "    if reduction_method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=variance_threshold)\n",
    "    else:\n",
    "        reducer = TruncatedSVD(n_components=min(flattened.shape))\n",
    "    \n",
    "    reduced = reducer.fit_transform(flattened)\n",
    "    reconstructed = reducer.inverse_transform(reduced)\n",
    "    variance_preserved = sum(reducer.explained_variance_ratio_) * 100\n",
    "    \n",
    "    print(f\"Variance preserved: {variance_preserved:.2f}%\")\n",
    "    return reconstructed.reshape(original_shape), variance_preserved\n",
    "\n",
    "def apply_convolution(image, kernel):\n",
    "    \"\"\"Apply convolution to an image\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        return np.stack([convolve2d(image[:,:,c], kernel, mode='same', boundary='wrap')\n",
    "                        for c in range(image.shape[2])], axis=2)\n",
    "    return convolve2d(image, kernel, mode='same', boundary='wrap')\n",
    "\n",
    "\n",
    "def get_convolution_kernels():\n",
    "    \"\"\"Return dictionary of common convolution kernels\"\"\"\n",
    "    return {\n",
    "        'edge_detection': np.array([[-1, -1, -1],\n",
    "                                  [-1,  8, -1],\n",
    "                                  [-1, -1, -1]]),\n",
    "        'sobel_x': np.array([[-1, 0, 1],\n",
    "                            [-2, 0, 2],\n",
    "                            [-1, 0, 1]]),\n",
    "        'sobel_y': np.array([[-1, -2, -1],\n",
    "                            [ 0,  0,  0],\n",
    "                            [ 1,  2,  1]]),\n",
    "        'color_contrast': np.array([[0, -1, 0],\n",
    "                                  [-1, 5, -1],\n",
    "                                  [0, -1, 0]])\n",
    "    }\n",
    "\n",
    "def apply_max_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply max pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.max(image[i*pool_size:(i+1)*pool_size, \n",
    "                                     j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def apply_avg_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply average pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.mean(image[i*pool_size:(i+1)*pool_size, \n",
    "                                      j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def flatten_batch(images):\n",
    "    \"\"\"Flatten batch of images\"\"\"\n",
    "    return images.reshape(len(images), -1)\n",
    "\n",
    "def remove_outliers(image, method='knn', n_neighbors=5, window_size=3):\n",
    "    \"\"\"Remove outliers from image using specified method\"\"\"\n",
    "    \n",
    "    original_shape = image.shape\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Handle different color channels separately\n",
    "    if len(original_shape) == 3:\n",
    "        cleaned_image = np.zeros_like(image)\n",
    "        for c in range(original_shape[2]):\n",
    "            cleaned_image[:,:,c] = remove_outliers(image[:,:,c], method, n_neighbors, window_size)\n",
    "        return cleaned_image\n",
    "    \n",
    "    if method.lower() == 'knn':\n",
    "        # Prepare data for KNN imputation\n",
    "        X = np.zeros((h*w, window_size**2))\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                # Extract local window\n",
    "                i_start = max(0, i - window_size//2)\n",
    "                i_end = min(h, i + window_size//2 + 1)\n",
    "                j_start = max(0, j - window_size//2)\n",
    "                j_end = min(w, j + window_size//2 + 1)\n",
    "                window = image[i_start:i_end, j_start:j_end].flatten()\n",
    "                # Pad if necessary\n",
    "                if len(window) < window_size**2:\n",
    "                    window = np.pad(window, (0, window_size**2 - len(window)), mode='edge')\n",
    "                X[i*w + j] = window\n",
    "        \n",
    "        # Apply KNN imputation\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        cleaned = imputer.fit_transform(X)\n",
    "        \n",
    "        # Reshape back to image\n",
    "        return cleaned[:,window_size**2//2].reshape(h, w)\n",
    "    \n",
    "    elif method.lower() == 'median':\n",
    "        return median_filter(image, size=window_size)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown outlier removal method: {method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb63759",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = os.listdir('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1')\n",
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = cv2.imread('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1/' + A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f330548",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('demo.png',demo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10  # Adjust this number based on your available memory\n",
    "# Use the same absolute folder that was used to create A\n",
    "base_dir = r'E:/@IIT_BBS/@Sem 1/ML/Final Project/P1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Convolution filter bank\n",
    "# ----------------------------------------------------------\n",
    "def apply_conv(image, kernel_size=3):\n",
    "    \"\"\"Apply Sobel, Laplacian, Gabor, DoG filters and return multi-channel output.\"\"\"\n",
    "    \n",
    "    # Ensure grayscale\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image loaded as None.\")\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "\n",
    "    filters = []\n",
    "\n",
    "    # Sobel X, Sobel Y\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    filters.extend([sobelx, sobely])\n",
    "\n",
    "    # Laplacian\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    filters.append(lap)\n",
    "\n",
    "    # 6 Gabor filters\n",
    "    for theta in np.arange(0, np.pi, np.pi / 6):\n",
    "        kernel = cv2.getGaborKernel((11, 11), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
    "        fimg = cv2.filter2D(gray, cv2.CV_64F, kernel)\n",
    "        filters.append(fimg)\n",
    "\n",
    "    # Difference of Gaussians\n",
    "    g1 = cv2.GaussianBlur(gray, (3, 3), 1)\n",
    "    g2 = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "    dog = g1 - g2\n",
    "    filters.append(dog)\n",
    "\n",
    "    # Stack channels → (H, W, C)\n",
    "    stacked = np.stack(filters, axis=-1)\n",
    "\n",
    "    # Normalize per channel (0-1)\n",
    "    norm = np.zeros_like(stacked, dtype=np.float32)\n",
    "    for c in range(stacked.shape[-1]):\n",
    "        ch = stacked[..., c]\n",
    "        norm[..., c] = (ch - ch.min()) / (ch.max() - ch.min() + 1e-6)\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Deterministic pooling (always ends at target_size × target_size)\n",
    "# ----------------------------------------------------------\n",
    "def apply_maxpooling(image, target_pool_size=8):\n",
    "    \"\"\"Resize down progressively, then enforce exact output size.\"\"\"\n",
    "    \n",
    "    pooled = image.astype(np.float32)\n",
    "\n",
    "    def safe_resize(img, new_w, new_h):\n",
    "        if img.ndim == 2 or img.shape[2] <= 4:\n",
    "            return cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            # Resize per-channel if many channels\n",
    "            resized = [cv2.resize(img[..., c], (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "                       for c in range(img.shape[2])]\n",
    "            return np.stack(resized, axis=-1)\n",
    "\n",
    "    # Progressive downsampling\n",
    "    while True:\n",
    "        h, w = pooled.shape[:2]\n",
    "        if min(h, w) <= target_pool_size:\n",
    "            break\n",
    "        pooled = safe_resize(pooled, max(1, w // 2), max(1, h // 2))\n",
    "\n",
    "    # Final deterministic size — essential fix\n",
    "    pooled = safe_resize(pooled, target_pool_size, target_pool_size)\n",
    "    return pooled\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Complete feature extractor\n",
    "# ----------------------------------------------------------\n",
    "def feature_extraction(image, kernel_size=3, target_pool_size=8):\n",
    "    \"\"\"Returns fixed-length handcrafted feature vector.\"\"\"\n",
    "    \n",
    "    conv = apply_conv(image, kernel_size=kernel_size)\n",
    "    pooled = apply_maxpooling(conv, target_pool_size=target_pool_size)\n",
    "\n",
    "    # Flatten pooled features\n",
    "    flat = pooled.flatten()\n",
    "\n",
    "    # Summary statistics\n",
    "    means = pooled.mean(axis=(0, 1))\n",
    "    stds = pooled.std(axis=(0, 1))\n",
    "\n",
    "    # Final vector is deterministic\n",
    "    vec = np.concatenate([flat, means, stds])\n",
    "    return vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd91353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. Batch feature extraction\n",
    "# ----------------------------------------------------------\n",
    "def batch_CFE(batch_size, base_dir, target_size=8):\n",
    "    \"\"\"Batch handcrafted feature extraction.\"\"\"\n",
    "    \n",
    "    processed = []\n",
    "    img_files = os.listdir(base_dir)\n",
    "\n",
    "    for i in tqdm(range(0, len(img_files), batch_size)):\n",
    "        batch_names = img_files[i:i + batch_size]\n",
    "        \n",
    "        for fname in batch_names:\n",
    "            path = os.path.join(base_dir, fname)\n",
    "            img = cv2.imread(path)\n",
    "\n",
    "            if img is None:\n",
    "                print(\"Skipping unreadable file:\", fname)\n",
    "                continue\n",
    "\n",
    "            feats = feature_extraction(img, kernel_size=3, target_pool_size=target_size)\n",
    "            processed.append(feats)\n",
    "\n",
    "    return np.array(processed)\n",
    "\n",
    "# feats = feature_extraction(processed_images[9], kernel_size=3,target_pool_size=8)\n",
    "# print(feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features = batch_CFE(batch_size=20,base_dir=base_dir, target_size=8)\n",
    "batch_features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
