{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b35f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import cv2\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde55ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_images(batch_images, target_size=(64, 64)):\n",
    "    \"\"\"Resize images to target size\"\"\"\n",
    "    processed_batch = [cv2.resize(img, target_size) for img in batch_images]\n",
    "    return np.array(processed_batch)\n",
    "\n",
    "def reduce_dimensions(images, reduction_method='pca', variance_threshold=0.95):\n",
    "    \"\"\"Apply dimension reduction using PCA or SVD\"\"\"\n",
    "    original_shape = images.shape\n",
    "    flattened = images.reshape(len(images), -1)\n",
    "    \n",
    "    if reduction_method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=variance_threshold)\n",
    "    else:\n",
    "        reducer = TruncatedSVD(n_components=min(flattened.shape))\n",
    "    \n",
    "    reduced = reducer.fit_transform(flattened)\n",
    "    reconstructed = reducer.inverse_transform(reduced)\n",
    "    variance_preserved = sum(reducer.explained_variance_ratio_) * 100\n",
    "    \n",
    "    print(f\"Variance preserved: {variance_preserved:.2f}%\")\n",
    "    return reconstructed.reshape(original_shape), variance_preserved\n",
    "\n",
    "def apply_convolution(image, kernel):\n",
    "    \"\"\"Apply convolution to an image\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        return np.stack([convolve2d(image[:,:,c], kernel, mode='same', boundary='wrap')\n",
    "                        for c in range(image.shape[2])], axis=2)\n",
    "    return convolve2d(image, kernel, mode='same', boundary='wrap')\n",
    "\n",
    "def get_convolution_kernels():\n",
    "    \"\"\"Return dictionary of common convolution kernels\"\"\"\n",
    "    return {\n",
    "        'edge_detection': np.array([[-1, -1, -1],\n",
    "                                  [-1,  8, -1],\n",
    "                                  [-1, -1, -1]]),\n",
    "        'sobel_x': np.array([[-1, 0, 1],\n",
    "                            [-2, 0, 2],\n",
    "                            [-1, 0, 1]]),\n",
    "        'sobel_y': np.array([[-1, -2, -1],\n",
    "                            [ 0,  0,  0],\n",
    "                            [ 1,  2,  1]]),\n",
    "        'color_contrast': np.array([[0, -1, 0],\n",
    "                                  [-1, 5, -1],\n",
    "                                  [0, -1, 0]])\n",
    "    }\n",
    "\n",
    "def apply_max_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply max pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.max(image[i*pool_size:(i+1)*pool_size, \n",
    "                                     j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def apply_avg_pooling(image, pool_size=2):\n",
    "    \"\"\"Apply average pooling to an image\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = h//pool_size, w//pool_size\n",
    "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i,j] = np.mean(image[i*pool_size:(i+1)*pool_size, \n",
    "                                      j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
    "    return pooled\n",
    "\n",
    "def flatten_batch(images):\n",
    "    \"\"\"Flatten batch of images\"\"\"\n",
    "    return images.reshape(len(images), -1)\n",
    "\n",
    "def remove_outliers(image, method='knn', n_neighbors=5, window_size=3):\n",
    "    \"\"\"Remove outliers from image using specified method\"\"\"\n",
    "    \n",
    "    original_shape = image.shape\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Handle different color channels separately\n",
    "    if len(original_shape) == 3:\n",
    "        cleaned_image = np.zeros_like(image)\n",
    "        for c in range(original_shape[2]):\n",
    "            cleaned_image[:,:,c] = remove_outliers(image[:,:,c], method, n_neighbors, window_size)\n",
    "        return cleaned_image\n",
    "    \n",
    "    if method.lower() == 'knn':\n",
    "        # Prepare data for KNN imputation\n",
    "        X = np.zeros((h*w, window_size**2))\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                # Extract local window\n",
    "                i_start = max(0, i - window_size//2)\n",
    "                i_end = min(h, i + window_size//2 + 1)\n",
    "                j_start = max(0, j - window_size//2)\n",
    "                j_end = min(w, j + window_size//2 + 1)\n",
    "                window = image[i_start:i_end, j_start:j_end].flatten()\n",
    "                # Pad if necessary\n",
    "                if len(window) < window_size**2:\n",
    "                    window = np.pad(window, (0, window_size**2 - len(window)), mode='edge')\n",
    "                X[i*w + j] = window\n",
    "        \n",
    "        # Apply KNN imputation\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        cleaned = imputer.fit_transform(X)\n",
    "        \n",
    "        # Reshape back to image\n",
    "        return cleaned[:,window_size**2//2].reshape(h, w)\n",
    "    \n",
    "    elif method.lower() == 'median':\n",
    "        return median_filter(image, size=window_size)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown outlier removal method: {method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb63759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = os.listdir('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1')\n",
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363ecb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ab537b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 4284, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread('E:/@IIT_BBS/@Sem 1/ML/Final Project/P1/' + A[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images in smaller batches to avoid memory issues\n",
    "batch_size = 10  # Adjust this number based on your available memory\n",
    "processed_images = []\n",
    "\n",
    "for i in range(0, len(A), batch_size):\n",
    "    batch_files = A[i:i + batch_size]\n",
    "    batch_images = [cv2.imread(\"P1/\" + filename) for filename in batch_files]\n",
    "    \n",
    "    # Preprocess current batch\n",
    "    batch_processed = preprocess_images(batch_images)\n",
    "    processed_images.extend(batch_processed)\n",
    "\n",
    "# Convert to numpy array for further processing\n",
    "processed_images = np.array(processed_images)\n",
    "\n",
    "# Apply dimension reduction on the processed images\n",
    "reduced_images, variance = reduce_dimensions(processed_images, \n",
    "                                          reduction_method='pca', \n",
    "                                          variance_threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bd072",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Reduced Image\", reduced_images[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fdeb44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
