{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zmBlgcj7ANmY"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "import cv2\n",
        "from scipy.signal import convolve2d\n",
        "from sklearn.impute import KNNImputer\n",
        "from scipy.ndimage import median_filter\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mzm5XdNbAUPh"
      },
      "outputs": [],
      "source": [
        "# def preprocess_images(batch_size,base_dir, target_size=(64, 64)):\n",
        "#     processed_images = []\n",
        "#     img_dir = os.listdir(base_dir)\n",
        "\n",
        "#     for i in tqdm(range(0, len(img_dir), batch_size)):\n",
        "#         batch_files = img_dir[i:i + batch_size]\n",
        "#         batch_images = []\n",
        "#         for filename in batch_files:\n",
        "#             filepath = os.path.join(base_dir, filename)\n",
        "#             img = cv2.imread(filepath) # read image\n",
        "#             img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) # resize image\n",
        "#             batch_images.append(img)\n",
        "\n",
        "#         if not batch_images:\n",
        "#             # nothing to process in this batch\n",
        "#             continue\n",
        "#         processed_images.extend(batch_images)\n",
        "#     return np.array(processed_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9d5bb26",
        "outputId": "72758c03-f429-4688-c83f-c9d5ad85807b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base_dir is set to: E:/@IIT_BBS/@Sem 1/ML/Final Project/P1\n"
          ]
        }
      ],
      "source": [
        "batch_size = 10  # Adjust this number based on your available memory\n",
        "# Use the same absolute folder that was used to create A\n",
        "base_dir = r'E:/@IIT_BBS/@Sem 1/ML/Final Project/P1'\n",
        "\n",
        "print(f\"base_dir is set to: {base_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "esnUgBNjHL7f"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 1. Custom convolution application with multiple filters\n",
        "# ----------------------------------------------------------\n",
        "def apply_conv(image, kernel_size=3):\n",
        "    \"\"\"Apply a bank of convolutional filters to each input channel and stack results as a multi-channel image.\n",
        "\n",
        "    Fix: ensure all intermediate OpenCV operations use a consistent depth (CV_32F) to avoid unsupported\n",
        "    source/destination format combinations.\n",
        "    \"\"\"\n",
        "    # Ensure list of single-channel arrays (use float32 consistently)\n",
        "    if image.ndim == 2:\n",
        "        channels = [image.copy().astype(np.float32)]\n",
        "    else:\n",
        "        channels = [image[..., c].astype(np.float32) for c in range(image.shape[2])]\n",
        "\n",
        "    filters = []\n",
        "\n",
        "    for ch in channels:\n",
        "        # Use CV_32F for all OpenCV ops to keep consistent dtypes\n",
        "        sobelx = cv2.Sobel(ch, cv2.CV_32F, 1, 0, ksize=kernel_size)\n",
        "        sobely = cv2.Sobel(ch, cv2.CV_32F, 0, 1, ksize=kernel_size)\n",
        "        filters.extend([sobelx, sobely])\n",
        "\n",
        "        # Laplacian with CV_32F\n",
        "        lap = cv2.Laplacian(ch, cv2.CV_32F)\n",
        "        filters.append(lap)\n",
        "\n",
        "        # Gabor filters (various orientations) - kernel as CV_32F, filter2D output CV_32F\n",
        "        for theta in np.arange(0, np.pi, np.pi / 6):  # 6 orientations\n",
        "            kernel = cv2.getGaborKernel((11, 11), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
        "            fimg = cv2.filter2D(ch, cv2.CV_32F, kernel)\n",
        "            filters.append(fimg)\n",
        "\n",
        "        # Difference of Gaussians (Gaussian retains float32)\n",
        "        g1 = cv2.GaussianBlur(ch, (3, 3), 1)\n",
        "        g2 = cv2.GaussianBlur(ch, (5, 5), 2)\n",
        "        dog = g1 - g2\n",
        "        filters.append(dog)\n",
        "\n",
        "    # Stack as multichannel image: H x W x (num_filters * num_input_channels)\n",
        "    # Ensure everything is float32 before stacking\n",
        "    filters = [f.astype(np.float32) for f in filters]\n",
        "    stacked = np.stack(filters, axis=-1)\n",
        "\n",
        "    # Normalize each channel to 0-1 safely\n",
        "    stacked = np.moveaxis(stacked, -1, 0)\n",
        "    normed = []\n",
        "    for ch in stacked:\n",
        "        mn = ch.min()\n",
        "        mx = ch.max()\n",
        "        if mx - mn < 1e-6:\n",
        "            normed.append(np.zeros_like(ch))\n",
        "        else:\n",
        "            normed.append((ch - mn) / (mx - mn))\n",
        "    stacked = np.moveaxis(np.array(normed, dtype=np.float32), 0, -1)\n",
        "    return stacked\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 2. Max pooling utility\n",
        "# ----------------------------------------------------------\n",
        "def apply_maxpooling(image, target_pool_size=8):\n",
        "    \"\"\"Apply pooling safely even when image has >4 channels, ensuring a fixed output spatial size.\"\"\"\n",
        "    pooled = image.copy().astype(np.float32)\n",
        "    if target_pool_size is None:\n",
        "        raise ValueError(\"target_pool_size must be provided.\")\n",
        "\n",
        "    def safe_resize(image, new_w, new_h):\n",
        "        if image.ndim == 2 or image.shape[2] <= 4:\n",
        "            return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        else:\n",
        "            resized_channels = [\n",
        "                cv2.resize(image[..., c], (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "                for c in range(image.shape[2])\n",
        "            ]\n",
        "            return np.stack(resized_channels, axis=-1)\n",
        "\n",
        "    # Iteratively reduce size until dimensions are close to target_pool_size\n",
        "    while True:\n",
        "        h, w = pooled.shape[:2]\n",
        "        if h <= target_pool_size and w <= target_pool_size: # Stop if both dimensions are <= target\n",
        "            break\n",
        "        # Reduce by half, ensuring dimensions don't become zero\n",
        "        pooled = safe_resize(pooled, max(1, w // 2), max(1, h // 2))\n",
        "\n",
        "    # Final resize to ensure exact target_pool_size x target_pool_size spatial dimensions\n",
        "    # This handles cases where pooled might be (7,7) or (9,9) after the loop, for target_pool_size=8\n",
        "    if pooled.shape[0] != target_pool_size or pooled.shape[1] != target_pool_size:\n",
        "        pooled = safe_resize(pooled, target_pool_size, target_pool_size)\n",
        "\n",
        "    # print(\"apply_maxpooling is running....\")\n",
        "    return pooled\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 3. Full feature extraction pipeline\n",
        "# ----------------------------------------------------------\n",
        "def feature_extraction(image, kernel_size=3, target_pool_size=7):\n",
        "    \"\"\"Extract rich handcrafted features using convolutional filter bank and pooling.\"\"\"\n",
        "    conv_output = apply_conv(image, kernel_size=kernel_size)\n",
        "    pooled_output = apply_maxpooling(conv_output, target_pool_size=target_pool_size)\n",
        "\n",
        "    # Flatten pooled output\n",
        "    features = pooled_output.flatten()\n",
        "\n",
        "    # Optionally add summary stats per channel (mean, std)\n",
        "    channel_means = pooled_output.mean(axis=(0, 1))\n",
        "    channel_stds = pooled_output.std(axis=(0, 1))\n",
        "\n",
        "    full_feature_vector = np.concatenate([features, channel_means, channel_stds])\n",
        "    # print(\"feature_extraction is running....\\n\")\n",
        "    return full_feature_vector\n",
        "\n",
        "\n",
        "# feats = feature_extraction(processed_images[9], kernel_size=3,target_pool_size=8)\n",
        "# print(feats.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VstrJfezHVTX"
      },
      "outputs": [],
      "source": [
        "def batch_CFE(batch_size,base_dir, target_size=7):\n",
        "    \"\"\" Batch Custom Feature Extraction using convolutional filter bank \"\"\"\n",
        "    processed_images = []\n",
        "    img_dir = os.listdir(base_dir)\n",
        "\n",
        "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
        "        batch_files = img_dir[i:i + batch_size]\n",
        "        batch_images = []\n",
        "        for filename in batch_files:\n",
        "            filepath = os.path.join(base_dir, filename)\n",
        "            img = cv2.imread(filepath) # read image\n",
        "            img = feature_extraction(img, kernel_size=3,target_pool_size=target_size)\n",
        "            batch_images.append(img)\n",
        "\n",
        "        if not batch_images:\n",
        "            # nothing to process in this batch\n",
        "            continue\n",
        "        processed_images.extend(batch_images)\n",
        "    return np.array(processed_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmlx2AUWHjkB",
        "outputId": "f6d4d92f-de5f-4d1e-c888-9f94e53f4537"
      },
      "outputs": [],
      "source": [
        "# from tqdm import tqdm\n",
        "# batch_features = batch_CFE(batch_size=20,base_dir=base_dir, target_size=5)\n",
        "# batch_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvolutionalFeatureExtractor:\n",
        "    def __init__(self, kernel_size=3, target_pool_size=8):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.target_pool_size = target_pool_size\n",
        "    \n",
        "    # ----------------------------------------------------------\n",
        "    # 1. Custom convolution application with multiple filters\n",
        "    # ----------------------------------------------------------\n",
        "    def apply_conv(image,grayscale = False, kernel_size=3):\n",
        "        \"\"\"Apply a bank of convolutional filters to each input channel and stack results as a multi-channel image.\n",
        "\n",
        "        Fix: ensure all intermediate OpenCV operations use a consistent depth (CV_32F) to avoid unsupported\n",
        "        source/destination format combinations.\n",
        "        \"\"\"\n",
        "        # Ensure list of single-channel arrays (use float32 consistently)\n",
        "        \n",
        "        if grayscale:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            channels = [gray.astype(np.float32)]\n",
        "        else:\n",
        "            channels = [image[..., c].astype(np.float32) for c in range(image.shape[2])]\n",
        "            \n",
        "        filters = []\n",
        "\n",
        "        for ch in channels:\n",
        "            # Use CV_32F for all OpenCV ops to keep consistent dtypes\n",
        "            sobelx = cv2.Sobel(ch, cv2.CV_32F, 1, 0, ksize=kernel_size)\n",
        "            sobely = cv2.Sobel(ch, cv2.CV_32F, 0, 1, ksize=kernel_size)\n",
        "            filters.extend([sobelx, sobely])\n",
        "\n",
        "            # Laplacian with CV_32F\n",
        "            lap = cv2.Laplacian(ch, cv2.CV_32F)\n",
        "            filters.append(lap)\n",
        "\n",
        "            # Gabor filters (various orientations) - kernel as CV_32F, filter2D output CV_32F\n",
        "            for theta in np.arange(0, np.pi, np.pi / 6):  # 6 orientations\n",
        "                kernel = cv2.getGaborKernel((11, 11), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
        "                fimg = cv2.filter2D(ch, cv2.CV_32F, kernel)\n",
        "                filters.append(fimg)\n",
        "\n",
        "            # Difference of Gaussians (Gaussian retains float32)\n",
        "            g1 = cv2.GaussianBlur(ch, (3, 3), 1)\n",
        "            g2 = cv2.GaussianBlur(ch, (5, 5), 2)\n",
        "            dog = g1 - g2\n",
        "            filters.append(dog)\n",
        "\n",
        "        # Stack as multichannel image: H x W x (num_filters * num_input_channels)\n",
        "        # Ensure everything is float32 before stacking\n",
        "        filters = [f.astype(np.float32) for f in filters]\n",
        "        stacked = np.stack(filters, axis=-1)\n",
        "\n",
        "        # Normalize each channel to 0-1 safely\n",
        "        stacked = np.moveaxis(stacked, -1, 0)\n",
        "        normed = []\n",
        "        for ch in stacked:\n",
        "            mn = ch.min()\n",
        "            mx = ch.max()\n",
        "            if mx - mn < 1e-6:\n",
        "                normed.append(np.zeros_like(ch))\n",
        "            else:\n",
        "                normed.append((ch - mn) / (mx - mn))\n",
        "        stacked = np.moveaxis(np.array(normed, dtype=np.float32), 0, -1)\n",
        "        return stacked\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # 2. Max pooling utility\n",
        "    # ----------------------------------------------------------\n",
        "    def apply_maxpooling(image, target_pool_size=8):\n",
        "        \"\"\"Apply pooling safely even when image has >4 channels, ensuring a fixed output spatial size.\"\"\"\n",
        "        pooled = image.copy().astype(np.float32)\n",
        "        if target_pool_size is None:\n",
        "            raise ValueError(\"target_pool_size must be provided.\")\n",
        "\n",
        "        def safe_resize(image, new_w, new_h):\n",
        "            if image.ndim == 2 or image.shape[2] <= 4:\n",
        "                return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "            else:\n",
        "                resized_channels = [\n",
        "                    cv2.resize(image[..., c], (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "                    for c in range(image.shape[2])\n",
        "                ]\n",
        "                return np.stack(resized_channels, axis=-1)\n",
        "\n",
        "        # Iteratively reduce size until dimensions are close to target_pool_size\n",
        "        while True:\n",
        "            h, w = pooled.shape[:2]\n",
        "            if h <= target_pool_size and w <= target_pool_size: # Stop if both dimensions are <= target\n",
        "                break\n",
        "            # Reduce by half, ensuring dimensions don't become zero\n",
        "            pooled = safe_resize(pooled, max(1, w // 2), max(1, h // 2))\n",
        "\n",
        "        # Final resize to ensure exact target_pool_size x target_pool_size spatial dimensions\n",
        "        # This handles cases where pooled might be (7,7) or (9,9) after the loop, for target_pool_size=8\n",
        "        if pooled.shape[0] != target_pool_size or pooled.shape[1] != target_pool_size:\n",
        "            pooled = safe_resize(pooled, target_pool_size, target_pool_size)\n",
        "\n",
        "        # print(\"apply_maxpooling is running....\")\n",
        "        return pooled\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # 3. Full feature extraction pipeline\n",
        "    # ----------------------------------------------------------\n",
        "    def feature_extraction(image, greyscale=False, kernel_size=3, target_pool_size=7):\n",
        "        \"\"\"Extract rich handcrafted features using convolutional filter bank and pooling.\"\"\"\n",
        "        conv_output = apply_conv(image,grayscale=greyscale, kernel_size=kernel_size)\n",
        "        pooled_output = apply_maxpooling(conv_output, target_pool_size=target_pool_size)\n",
        "\n",
        "        # Flatten pooled output\n",
        "        features = pooled_output.flatten()\n",
        "\n",
        "        # Optionally add summary stats per channel (mean, std)\n",
        "        channel_means = pooled_output.mean(axis=(0, 1))\n",
        "        channel_stds = pooled_output.std(axis=(0, 1))\n",
        "\n",
        "        full_feature_vector = np.concatenate([features, channel_means, channel_stds])\n",
        "        # print(\"feature_extraction is running....\\n\")\n",
        "        return full_feature_vector\n",
        "\n",
        "\n",
        "    # feats = feature_extraction(processed_images[9], kernel_size=3,target_pool_size=8)\n",
        "    # print(feats.shape)\n",
        "    def batch_CFE(batch_size,base_dir,greyscale=False, kernel_size=3, target_size=7):\n",
        "        \"\"\" Batch Custom Feature Extraction using convolutional filter bank \"\"\"\n",
        "        processed_images = []\n",
        "        img_dir = os.listdir(base_dir)\n",
        "\n",
        "        for i in tqdm(range(0, len(img_dir), batch_size)):\n",
        "            batch_files = img_dir[i:i + batch_size]\n",
        "            batch_images = []\n",
        "            for filename in batch_files:\n",
        "                filepath = os.path.join(base_dir, filename)\n",
        "                img = cv2.imread(filepath) # read image\n",
        "                img = feature_extraction(img, kernel_size=3,target_pool_size=target_size)\n",
        "                batch_images.append(img)\n",
        "\n",
        "            if not batch_images:\n",
        "                # nothing to process in this batch\n",
        "                continue\n",
        "            processed_images.extend(batch_images)\n",
        "        return np.array(processed_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZVrAoFX_vXH9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22/22 [2:34:40<00:00, 421.85s/it]  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(427, 810)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "batch_features = ConvolutionalFeatureExtractor.batch_CFE(batch_size=20,base_dir=base_dir,greyscale=False, kernel_size=3, target_size=5)\n",
        "batch_features.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
