{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmBlgcj7ANmY"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "import cv2\n",
        "from scipy.signal import convolve2d\n",
        "from sklearn.impute import KNNImputer\n",
        "from scipy.ndimage import median_filter\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(batch_size,base_dir, target_size=(64, 64)):\n",
        "    processed_images = []\n",
        "    img_dir = os.listdir(base_dir)\n",
        "\n",
        "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
        "        batch_files = img_dir[i:i + batch_size]\n",
        "        batch_images = []\n",
        "        for filename in batch_files:\n",
        "            filepath = os.path.join(base_dir, filename)\n",
        "            img = cv2.imread(filepath) # read image\n",
        "            img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) # resize image\n",
        "            batch_images.append(img)\n",
        "\n",
        "        if not batch_images:\n",
        "            # nothing to process in this batch\n",
        "            continue\n",
        "        processed_images.extend(batch_images)\n",
        "    return np.array(processed_images)\n",
        "\n",
        "\n",
        "def reduce_dimensions(images, reduction_method='pca', variance_threshold=0.95):\n",
        "    \"\"\"Apply dimension reduction using PCA or SVD\"\"\"\n",
        "    original_shape = images.shape\n",
        "    flattened = images.reshape(len(images), -1)\n",
        "\n",
        "    if reduction_method.lower() == 'pca':\n",
        "        reducer = PCA(n_components=variance_threshold)\n",
        "    else:\n",
        "        reducer = TruncatedSVD(n_components=min(flattened.shape))\n",
        "\n",
        "    reduced = reducer.fit_transform(flattened)\n",
        "    reconstructed = reducer.inverse_transform(reduced)\n",
        "    variance_preserved = sum(reducer.explained_variance_ratio_) * 100\n",
        "\n",
        "    print(f\"Variance preserved: {variance_preserved:.2f}%\")\n",
        "    return reconstructed.reshape(original_shape), variance_preserved\n",
        "\n",
        "def apply_convolution(image, kernel):\n",
        "    \"\"\"Apply convolution to an image\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        return np.stack([convolve2d(image[:,:,c], kernel, mode='same', boundary='wrap')\n",
        "                        for c in range(image.shape[2])], axis=2)\n",
        "    return convolve2d(image, kernel, mode='same', boundary='wrap')\n",
        "\n",
        "\n",
        "def get_convolution_kernels():\n",
        "    \"\"\"Return dictionary of common convolution kernels\"\"\"\n",
        "    return {\n",
        "        'edge_detection': np.array([[-1, -1, -1],\n",
        "                                  [-1,  8, -1],\n",
        "                                  [-1, -1, -1]]),\n",
        "        'sobel_x': np.array([[-1, 0, 1],\n",
        "                            [-2, 0, 2],\n",
        "                            [-1, 0, 1]]),\n",
        "        'sobel_y': np.array([[-1, -2, -1],\n",
        "                            [ 0,  0,  0],\n",
        "                            [ 1,  2,  1]]),\n",
        "        'color_contrast': np.array([[0, -1, 0],\n",
        "                                  [-1, 5, -1],\n",
        "                                  [0, -1, 0]])\n",
        "    }\n",
        "\n",
        "def apply_max_pooling(image, pool_size=2):\n",
        "    \"\"\"Apply max pooling to an image\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    new_h, new_w = h//pool_size, w//pool_size\n",
        "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
        "\n",
        "    for i in range(new_h):\n",
        "        for j in range(new_w):\n",
        "            pooled[i,j] = np.max(image[i*pool_size:(i+1)*pool_size,\n",
        "                                     j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
        "    return pooled\n",
        "\n",
        "def apply_avg_pooling(image, pool_size=2):\n",
        "    \"\"\"Apply average pooling to an image\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    new_h, new_w = h//pool_size, w//pool_size\n",
        "    pooled = np.zeros((new_h, new_w) + image.shape[2:])\n",
        "\n",
        "    for i in range(new_h):\n",
        "        for j in range(new_w):\n",
        "            pooled[i,j] = np.mean(image[i*pool_size:(i+1)*pool_size,\n",
        "                                      j*pool_size:(j+1)*pool_size], axis=(0,1))\n",
        "    return pooled\n",
        "\n",
        "def flatten_batch(images):\n",
        "    \"\"\"Flatten batch of images\"\"\"\n",
        "    return images.reshape(len(images), -1)\n",
        "\n",
        "def remove_outliers(image, method='knn', n_neighbors=5, window_size=3):\n",
        "    \"\"\"Remove outliers from image using specified method\"\"\"\n",
        "\n",
        "    original_shape = image.shape\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    # Handle different color channels separately\n",
        "    if len(original_shape) == 3:\n",
        "        cleaned_image = np.zeros_like(image)\n",
        "        for c in range(original_shape[2]):\n",
        "            cleaned_image[:,:,c] = remove_outliers(image[:,:,c], method, n_neighbors, window_size)\n",
        "        return cleaned_image\n",
        "\n",
        "    if method.lower() == 'knn':\n",
        "        # Prepare data for KNN imputation\n",
        "        X = np.zeros((h*w, window_size**2))\n",
        "        for i in range(h):\n",
        "            for j in range(w):\n",
        "                # Extract local window\n",
        "                i_start = max(0, i - window_size//2)\n",
        "                i_end = min(h, i + window_size//2 + 1)\n",
        "                j_start = max(0, j - window_size//2)\n",
        "                j_end = min(w, j + window_size//2 + 1)\n",
        "                window = image[i_start:i_end, j_start:j_end].flatten()\n",
        "                # Pad if necessary\n",
        "                if len(window) < window_size**2:\n",
        "                    window = np.pad(window, (0, window_size**2 - len(window)), mode='edge')\n",
        "                X[i*w + j] = window\n",
        "\n",
        "        # Apply KNN imputation\n",
        "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
        "        cleaned = imputer.fit_transform(X)\n",
        "\n",
        "        # Reshape back to image\n",
        "        return cleaned[:,window_size**2//2].reshape(h, w)\n",
        "\n",
        "    elif method.lower() == 'median':\n",
        "        return median_filter(image, size=window_size)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown outlier removal method: {method}\")"
      ],
      "metadata": {
        "id": "Mzm5XdNbAUPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20UTiy8_AZ14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv35Z6BIAiqB",
        "outputId": "b2b20fe0-45c4-482d-a627-2c4d58b40316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TyS4mEOcAo4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9d5bb26",
        "outputId": "72758c03-f429-4688-c83f-c9d5ad85807b"
      },
      "source": [
        "batch_size = 10\n",
        "base_dir = '/content/drive/MyDrive/dataset/P1'\n",
        "print(f\"base_dir is set to: {base_dir}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_dir is set to: /content/drive/MyDrive/dataset/P1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 1. Custom convolution application with multiple filters\n",
        "# ----------------------------------------------------------\n",
        "def apply_conv(image,kernel_size=3):\n",
        "    \"\"\"Apply a bank of convolutional filters and stack results as multi-channel image.\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "\n",
        "    filters = []\n",
        "\n",
        "    # Sobel filters\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
        "    filters.extend([sobelx, sobely])\n",
        "\n",
        "    # Laplacian\n",
        "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "    filters.append(lap)\n",
        "\n",
        "    # Gabor filters (various orientations)\n",
        "    for theta in np.arange(0, np.pi, np.pi / 6):  # 6 orientations\n",
        "        kernel = cv2.getGaborKernel((11, 11), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
        "        fimg = cv2.filter2D(gray, cv2.CV_64F, kernel)\n",
        "        filters.append(fimg)\n",
        "\n",
        "    # Difference of Gaussians\n",
        "    g1 = cv2.GaussianBlur(gray, (3, 3), 1)\n",
        "    g2 = cv2.GaussianBlur(gray, (5, 5), 2)\n",
        "    dog = g1 - g2\n",
        "    filters.append(dog)\n",
        "\n",
        "    # Stack as multichannel image\n",
        "    stacked = np.stack(filters, axis=-1)\n",
        "\n",
        "    # Normalize each channel to 0-1\n",
        "    stacked = np.array([(ch - ch.min()) / (ch.max() - ch.min() + 1e-6) for ch in np.moveaxis(stacked, -1, 0)])\n",
        "    stacked = np.moveaxis(stacked, 0, -1)\n",
        "    # print(\"apply_conv is running....\")\n",
        "    return stacked\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 2. Max pooling utility\n",
        "# ----------------------------------------------------------\n",
        "def apply_maxpooling(image, target_pool_size=8):\n",
        "    \"\"\"Apply pooling safely even when image has >4 channels, ensuring a fixed output spatial size.\"\"\"\n",
        "    pooled = image.copy().astype(np.float32)\n",
        "    if target_pool_size is None:\n",
        "        raise ValueError(\"target_pool_size must be provided.\")\n",
        "\n",
        "    def safe_resize(image, new_w, new_h):\n",
        "        if image.ndim == 2 or image.shape[2] <= 4:\n",
        "            return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        else:\n",
        "            resized_channels = [\n",
        "                cv2.resize(image[..., c], (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "                for c in range(image.shape[2])\n",
        "            ]\n",
        "            return np.stack(resized_channels, axis=-1)\n",
        "\n",
        "    # Iteratively reduce size until dimensions are close to target_pool_size\n",
        "    while True:\n",
        "        h, w = pooled.shape[:2]\n",
        "        if h <= target_pool_size and w <= target_pool_size: # Stop if both dimensions are <= target\n",
        "            break\n",
        "        # Reduce by half, ensuring dimensions don't become zero\n",
        "        pooled = safe_resize(pooled, max(1, w // 2), max(1, h // 2))\n",
        "\n",
        "    # Final resize to ensure exact target_pool_size x target_pool_size spatial dimensions\n",
        "    # This handles cases where pooled might be (7,7) or (9,9) after the loop, for target_pool_size=8\n",
        "    if pooled.shape[0] != target_pool_size or pooled.shape[1] != target_pool_size:\n",
        "        pooled = safe_resize(pooled, target_pool_size, target_pool_size)\n",
        "\n",
        "    # print(\"apply_maxpooling is running....\")\n",
        "    return pooled\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 3. Full feature extraction pipeline\n",
        "# ----------------------------------------------------------\n",
        "def feature_extraction(image, kernel_size=3, target_pool_size=7):\n",
        "    \"\"\"Extract rich handcrafted features using convolutional filter bank and pooling.\"\"\"\n",
        "    conv_output = apply_conv(image, kernel_size=kernel_size)\n",
        "    pooled_output = apply_maxpooling(conv_output, target_pool_size=target_pool_size)\n",
        "\n",
        "    # Flatten pooled output\n",
        "    features = pooled_output.flatten()\n",
        "\n",
        "    # Optionally add summary stats per channel (mean, std)\n",
        "    channel_means = pooled_output.mean(axis=(0, 1))\n",
        "    channel_stds = pooled_output.std(axis=(0, 1))\n",
        "\n",
        "    full_feature_vector = np.concatenate([features, channel_means, channel_stds])\n",
        "    # print(\"feature_extraction is running....\\n\")\n",
        "    return full_feature_vector\n",
        "\n",
        "\n",
        "# feats = feature_extraction(processed_images[9], kernel_size=3,target_pool_size=8)\n",
        "# print(feats.shape)\n"
      ],
      "metadata": {
        "id": "esnUgBNjHL7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_CFE(batch_size,base_dir, target_size=7):\n",
        "    \"\"\" Batch Custom Feature Extraction using convolutional filter bank \"\"\"\n",
        "    processed_images = []\n",
        "    img_dir = os.listdir(base_dir)\n",
        "\n",
        "    for i in tqdm(range(0, len(img_dir), batch_size)):\n",
        "        batch_files = img_dir[i:i + batch_size]\n",
        "        batch_images = []\n",
        "        for filename in batch_files:\n",
        "            filepath = os.path.join(base_dir, filename)\n",
        "            img = cv2.imread(filepath) # read image\n",
        "            img = feature_extraction(img, kernel_size=3,target_pool_size=target_size)\n",
        "            batch_images.append(img)\n",
        "\n",
        "        if not batch_images:\n",
        "            # nothing to process in this batch\n",
        "            continue\n",
        "        processed_images.extend(batch_images)\n",
        "    return np.array(processed_images)"
      ],
      "metadata": {
        "id": "VstrJfezHVTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "batch_features = batch_CFE(batch_size=20,base_dir=base_dir, target_size=8)\n",
        "batch_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmlx2AUWHjkB",
        "outputId": "f6d4d92f-de5f-4d1e-c888-9f94e53f4537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [1:59:39<00:00, 326.34s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(435, 660)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "AaHNScEJICJD",
        "outputId": "ac619246-c8a6-4ace-8426-5a8c2f34b79b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'batch_features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-418326534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'batch_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVrAoFX_vXH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}